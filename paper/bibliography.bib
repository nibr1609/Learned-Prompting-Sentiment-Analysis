@article{gemma_2025,
    title={Gemma 3},
    url={https://goo.gle/Gemma3Report},
    publisher={Kaggle},
    author={Google},
    year={2025}
}

@misc{bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1810.04805}, 
}

@inproceedings{
deberta,
title={DEBERTA: DECODING-ENHANCED BERT WITH DISENTANGLED ATTENTION},
author={Pengcheng He and Xiaodong Liu and Jianfeng Gao and Weizhu Chen},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=XPZIaotutsD}
}

@article{roberta,
  author    = {Yinhan Liu and
               Myle Ott and
               Naman Goyal and
               Jingfei Du and
               Mandar Joshi and
               Danqi Chen and
               Omer Levy and
               Mike Lewis and
               Luke Zettlemoyer and
               Veselin Stoyanov},
  title     = {RoBERTa: {A} Robustly Optimized {BERT} Pretraining Approach},
  journal   = {CoRR},
  volume    = {abs/1907.11692},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.11692},
  archivePrefix = {arXiv},
  eprint    = {1907.11692},
  timestamp = {Thu, 01 Aug 2019 08:59:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-11692.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{distilRoBERTa,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.01108}
}

@misc{discriminativeMullick,
      title={Discriminative Models Can Still Outperform Generative Models in Aspect Based Sentiment Analysis}, 
      author={Dhruv Mullick and Alona Fyshe and Bilal Ghanem},
      year={2023},
      eprint={2206.02892},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2206.02892}, 
}

@misc{brown2020languagemodelsfewshotlearners,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2005.14165}, 
}

@inproceedings{zhang-etal-2024-sentiment,
    title = "Sentiment Analysis in the Era of Large Language Models: A Reality Check",
    author = "Zhang, Wenxuan  and
      Deng, Yue  and
      Liu, Bing  and
      Pan, Sinno  and
      Bing, Lidong",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2024",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-naacl.246/",
    doi = "10.18653/v1/2024.findings-naacl.246",
    pages = "3881--3906",
    abstract = "Sentiment analysis (SA) has been a long-standing research area in natural language processing. With the recent advent of large language models (LLMs), there is great potential for their employment on SA problems. However, the extent to which current LLMs can be leveraged for different sentiment analysis tasks remains unclear. This paper aims to provide a comprehensive investigation into the capabilities of LLMs in performing various sentiment analysis tasks, from conventional sentiment classification to aspect-based sentiment analysis and multifaceted analysis of subjective texts. We evaluate performance across 13 tasks on 26 datasets and compare the results against small language models (SLMs) trained on domain-specific datasets. Our study reveals that while LLMs demonstrate satisfactory performance in simpler tasks, they lag behind in more complex tasks requiring a deeper understanding of specific sentiment phenomena or structured sentiment information. However, LLMs significantly outperform SLMs in few-shot learning settings, suggesting their potential when annotation resources are limited. We also highlight the limitations of current evaluation practices in assessing LLMs' SA abilities and propose a novel benchmark, SentiEval, for a more comprehensive and realistic evaluation. Data and code are available at \url{https://github.com/DAMO-NLP-SG/LLM-Sentiment}."
}

@article{subsetSelection,
author = {Nemhauser, G. L. and Wolsey, L. A. and Fisher, M. L.},
title = {An analysis of approximations for maximizing submodular set functions--I},
year = {1978},
issue_date = {December  1978},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {14},
number = {1},
issn = {0025-5610},
url = {https://doi.org/10.1007/BF01588971},
doi = {10.1007/BF01588971},
abstract = {LetN be a finite set andz be a real-valued function defined on the set of subsets ofN that satisfies z(S)+z(T)\'{z}z(S\'{z}T)+z(S\'{z}T) for allS, T inN. Such a function is called submodular. We consider the problem maxS\'{z}N{a(S):|S|≤K,z(S) submodular}.Several hard combinatorial optimization problems can be posed in this framework. For example, the problem of finding a maximum weight independent set in a matroid, when the elements of the matroid are colored and the elements of the independent set can have no more thanK colors, is in this class. The uncapacitated location problem is a special case of this matroid optimization problem.We analyze greedy and local improvement heuristics and a linear programming relaxation for this problem. Our results are worst case bounds on the quality of the approximations. For example, whenz(S) is nondecreasing andz(0) = 0, we show that a "greedy" heuristic always produces a solution whose value is at least 1 \'{z}[(K \'{z} 1)/K]K times the optimal value. This bound can be achieved for eachK and has a limiting value of (e \'{z} 1)/e, where e is the base of the natural logarithm.},
journal = {Math. Program.},
month = dec,
pages = {265–294},
numpages = {30},
keywords = {Greedy Algorithm, Heuristics, Interchange Algorithm, Linear Programming, Matroid Optimization, Submodular Set Functions}
}

@InProceedings{ensemble,
author="Tran, Vu
and Matsui, Tomoko",
editor="Suzumura, Toyotaro
and Bono, Mayumi",
title="Improving LLM Prompting with Ensemble of Instructions: A Case Study on Sentiment Analysis",
booktitle="New Frontiers in Artificial Intelligence",
year="2024",
publisher="Springer Nature Singapore",
address="Singapore",
pages="299--305",
abstract="In the era of large language models, exploring the capability of a large language model is a trending research direction where one is prompt engineering aiming at drafting the best instructions to ask a large language model. We assume that a selected large language model has a certain knowledge and capability of a given task, and the way to ask is strongly related to the task's performance. This is certainly useful when we don't have sufficient resource for finetuning or aligning the large language model. Following that direction, we present our approach towards improving the effectiveness of prompting a large language model by finding an optimal ensemble of instructions by using the large language model's self-generated instructions and labeled data. A case study on sentiment analysis is carried out in a preliminary experiment. The positive results of our case study shows that the approach is promising.",
isbn="978-981-97-3076-6"
}


@inproceedings{emollms, series={KDD ’24},
   title={EmoLLMs: A Series of Emotional Large Language Models and Annotation Tools for Comprehensive Affective Analysis},
   url={http://dx.doi.org/10.1145/3637528.3671552},
   DOI={10.1145/3637528.3671552},
   booktitle={Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
   publisher={ACM},
   author={Liu, Zhiwei and Yang, Kailai and Xie, Qianqian and Zhang, Tianlin and Ananiadou, Sophia},
   year={2024},
   month=aug, pages={5487–5496},
   collection={KDD ’24} }

@article{promptlearning,
title = {Efficient utilization of pre-trained models: A review of sentiment analysis via prompt learning},
journal = {Knowledge-Based Systems},
volume = {283},
pages = {111148},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2023.111148},
url = {https://www.sciencedirect.com/science/article/pii/S0950705123008985},
author = {Kun Bu and Yuanchao Liu and Xiaolong Ju},
keywords = {Sentiment analysis, Prompt learning, Word embedding, Pre-trained models, Natural language processing},
abstract = {Sentiment analysis is one of the traditional well-known tasks in Natural Language Processing (NLP) research. In recent years, Pre-trained Models (PMs) have become one of the frontiers of NLP, and the knowledge in PMs is usually leveraged to improve machine learning models' performance for a variety of downstream NLP tasks including sentiment analysis. However, there are also some shortcomings in PM-based approaches. For example, many studies pointed out there are gaps between pre-training and fine-tuning. In addition, because of the time-consuming and high-cost data annotation process, the labeled training data are usually precious and scarce, which often leads to the over-fitting of models. The recent advent of prompt learning technology provides a promising solution to the above challenges. In this paper, we first discussed the background of prompt learning and its basic principle. Prompt learning changes the model input by adding templates, allowing learning tasks to adapt actively to pre-trained models, and therefore can promote the innovation and applicability of pre-trained models. Then we investigated the evolution of sentiment analysis and explored the application of prompt learning to different sentiment analysis tasks. Our research and review show that prompt learning is more suitable for sentiment analysis tasks and can achieve good performance. Finally, we also provided some future research directions on prompt-based sentiment analysis. Our survey demonstrated that prompt learning can facilitate the efficient utilization of pre-trained models in sentiment analysis and other tasks, which makes it a new paradigm worthy of further exploration.}
}

@InProceedings{svm,
author="Korovkinas, Konstantinas
and Dan{\.{e}}nas, Paulius
and Gar{\v{s}}va, Gintautas",
editor="Dama{\v{s}}evi{\v{c}}ius, Robertas
and Vasiljevien{\.{e}}, Giedr{\.{e}}",
title="SVM Accuracy and Training Speed Trade-Off in Sentiment Analysis Tasks",
booktitle="Information and Software Technologies",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="227--239",
abstract="SVM technique is one of the best techniques to classify data, but it has a slow performance in the big data arrays. This paper introduces the method to improve the speed of SVM classification in sentiment analysis by reducing the training set. The method was tested on the Stanford Twitter sentiment corpus dataset and Amazon customer reviews dataset. The results show that the execution time of the introduced method outperforms the standard SVM classification method.",
isbn="978-3-319-99972-2"
}



@inbook{bertsentiment,
   title={BERT-Based Sentiment Analysis: A Software Engineering Perspective},
   ISBN={9783030864729},
   ISSN={1611-3349},
   url={http://dx.doi.org/10.1007/978-3-030-86472-9_13},
   DOI={10.1007/978-3-030-86472-9_13},
   booktitle={Database and Expert Systems Applications},
   publisher={Springer International Publishing},
   author={Batra, Himanshu and Punn, Narinder Singh and Sonbhadra, Sanjay Kumar and Agarwal, Sonali},
   year={2021},
   pages={138–148} }



@article{promptengineering,
author = {Lo, Leo S.},
title = {The Art and Science of Prompt Engineering: A New Literacy in the Information Age},
journal = {Internet Reference Services Quarterly},
volume = {27},
number = {4},
pages = {203--210},
year = {2023},
publisher = {Routledge},
doi = {10.1080/10875301.2023.2227621},


URL = { 
    
        https://doi.org/10.1080/10875301.2023.2227621
    
    

},
eprint = { 
    
        https://doi.org/10.1080/10875301.2023.2227621
    
    

}
,
    abstract = { The novel discipline of prompt-engineering is a combination of artificial intelligence, linguistics, and user experience design. Crafting effective prompts for AI models like OpenAI’s GPT can optimize the quality of generated output, especially in reference services. The article explains the CLEAR Framework—a guiding tool that incorporates principles of conciseness, logic, explicitness, adaptability, and reflectiveness in prompt crafting. Despite challenges including biases, ethical concerns, and keeping up with rapidly evolving AI capabilities, the field also presents opportunities for growth. The article concludes with a call to action for library professionals to embrace and master prompt-engineering as an essential skill. }
}


@article{traditionalSA,
author = {Fang, Xing and Zhan, Justin},
year = {2015},
month = {12},
pages = {},
title = {Sentiment analysis using product review data},
volume = {2},
journal = {J Big Data},
doi = {10.1186/s40537-015-0015-2}
}